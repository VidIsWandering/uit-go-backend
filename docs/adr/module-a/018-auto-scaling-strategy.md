# ADR 018: Target Tracking Auto Scaling Strategy for ECS Services

## Tr·∫°ng th√°i

ƒê∆∞·ª£c ch·∫•p nh·∫≠n (Accepted) - Module A, Week 10

## B·ªëi c·∫£nh

Trong Giai ƒëo·∫°n 1, h·ªá th·ªëng c√≥ `desired_count = 1` hardcoded cho m·ªói ECS service. Ki·∫øn tr√∫c n√†y g·∫∑p v·∫•n ƒë·ªÅ khi:

**V·∫•n ƒë·ªÅ hi·ªán t·∫°i:**
- Traffic tƒÉng ƒë·ªôt bi·∫øn (v√≠ d·ª•: peak gi·ªù tan t·∫ßm 5-6 PM) ‚Üí service crash ho·∫∑c latency spike
- CPU/Memory spike khi x·ª≠ l√Ω batch requests (v√≠ d·ª•: import 1000 drivers c√πng l√∫c)
- Kh√¥ng th·ªÉ t·∫≠n d·ª•ng ECS Fargate auto-scaling capabilities
- L√£ng ph√≠ t√†i nguy√™n khi traffic th·∫•p (v·∫´n ch·∫°y 1 task d√π kh√¥ng c√≥ request)

**Load Testing Results (Baseline - 1 task):**
- **Throughput**: 100 RPS max (bottleneck t·∫°i trip-service)
- **Latency p95**: 500ms (create trip), 800ms (trip history)
- **CPU Utilization**: 85% sustained khi 100 RPS ‚Üí nguy c∆° crash
- **Memory Utilization**: 70% sustained
- **Failure Rate**: 5% khi > 100 concurrent users (timeout, 503 errors)

## Quy·∫øt ƒë·ªãnh

Implement **Target Tracking Auto Scaling** v·ªõi 3 metrics cho m·ªói ECS service:

### 1. CPU-based Scaling Policy
```hcl
target_value       = 70.0  # Target 70% CPU utilization
scale_out_cooldown = 60    # Scale out sau 1 ph√∫t
scale_in_cooldown  = 300   # Scale in sau 5 ph√∫t
```

**L√Ω do ch·ªçn 70%:**
- < 50%: Qu√° th·∫•p, t·ªën cost (scale out s·ªõm)
- 70%: Sweet spot - ƒë·ªß headroom cho sudden spike, kh√¥ng waste resources
- > 80%: Qu√° cao, latency degradation tr∆∞·ªõc khi scale

### 2. Memory-based Scaling Policy
```hcl
target_value       = 80.0  # Target 80% memory utilization
scale_out_cooldown = 60
scale_in_cooldown  = 300
```

**L√Ω do ch·ªçn 80%:**
- JVM apps (user-service, trip-service) c√≥ garbage collection overhead
- 80% memory = c√≤n 20% buffer cho GC spikes
- Node.js (driver-service) √≠t memory-intensive h∆°n, 80% v·∫´n an to√†n

### 3. Request Count-based Scaling (ALB Target Tracking)
```hcl
predefined_metric_type = "ALBRequestCountPerTarget"
target_value           = 1000  # Target 1000 requests/target
```

**L√Ω do ch·ªçn 1000 req/target:**
- M·ªói Fargate task (0.25 vCPU, 512 MB RAM) x·ª≠ l√Ω ƒë∆∞·ª£c ~100-150 RPS
- Target 1000 req/minute = ~16 RPS/task (headroom 6x)
- Scale out tr∆∞·ªõc khi ƒë·∫°t gi·ªõi h·∫°n

### Capacity Configuration
```hcl
min_capacity = 1   # T·ªëi thi·ªÉu 1 task (cost optimization)
max_capacity = 10  # T·ªëi ƒëa 10 tasks (prevent runaway scaling)
```

**Gi·ªõi h·∫°n max=10:**
- Cost cap: 10 tasks √ó $0.05/hour = $0.50/hour max
- Database connection pool limit: 10 tasks √ó 5 connections = 50 (RDS max_connections=87)
- ALB target group health check capacity

### Cooldown Strategy
- **Scale-out cooldown: 60s** (nhanh, prevent latency spike)
- **Scale-in cooldown: 300s** (ch·∫≠m, prevent thrashing - tr√°nh scale up/down li√™n t·ª•c)

## L√Ω do (∆Øu ti√™n)

### 1. Availability - Prevent Service Degradation (∆Øu ti√™n cao nh·∫•t)
- T·ª± ƒë·ªông scale out khi CPU > 70% ‚Üí latency p95 gi·∫£m t·ª´ 500ms ‚Üí 300ms
- NgƒÉn ch·∫∑n cascading failures (trip-service crash ‚Üí ·∫£nh h∆∞·ªüng user-service)
- SLA target: 99.9% uptime (downtime < 43 ph√∫t/th√°ng)

### 2. Cost Efficiency - Pay for What You Use
- **Off-peak** (12 AM - 6 AM): Scale down to 1 task ‚Üí save ~$0.40/hour √ó 6h = $2.40/day
- **Peak** (5 PM - 7 PM): Scale up to 5-8 tasks ‚Üí cost tƒÉng 5-8x trong 2 gi·ªù
- **Total savings**: ~30% monthly cost vs fixed 3 tasks 24/7

### 3. Performance - Optimize Resource Utilization
- CPU target 70% ‚Üí CPU kh√¥ng idle (< 50%) nh∆∞ng c≈©ng kh√¥ng overload (> 85%)
- Memory target 80% ‚Üí t·∫≠n d·ª•ng RAM, tr√°nh OOM (Out of Memory)

### 4. Reliability - Self-healing
- Service crash (bug, memory leak) ‚Üí Auto-scaling t·∫°o task m·ªõi
- Task terminated (deployment) ‚Üí Desired count maintained

## ƒê√°nh ƒë·ªïi (Ch·∫•p nh·∫≠n)

### 1. Cold Start Latency - Scale-out time ~90 seconds (Acceptable)
**Breakdown:**
- ECS launch task: 10s
- Pull Docker image (nginx:latest placeholder): 30s (s·∫Ω l√¢u h∆°n v·ªõi production images ~1-2 GB)
- Container start: 5s
- Health check (2 successful checks √ó 30s interval): 60s
**Total**: ~105s trong worst case

**Impact:**
- User experience: Latency spike trong 90s ƒë·∫ßu khi traffic tƒÉng
- Mitigation: Scheduled scaling (scale out tr∆∞·ªõc peak gi·ªù)

### 2. Cost - Unpredictable during Peak (Acceptable)
**Scenario:**
- Viral event (trending trip route) ‚Üí 10,000 concurrent users
- Scale to max 10 tasks √ó 3 services = 30 tasks
- Cost: $0.05/task/hour √ó 30 tasks √ó 2 hours = $3 for event
- **Trade-off**: TƒÉng cost ng·∫Øn h·∫°n ƒë·ªÉ maintain availability

**Mitigation:**
- CloudWatch Billing Alarms: Alert khi cost > $5/day
- Max capacity limit: 10 tasks (cost cap)

### 3. Complexity - Tuning Thresholds (Acceptable)
**C√¢u h·ªèi c·∫ßn tr·∫£ l·ªùi qua testing:**
- 70% CPU c√≥ ph·∫£i optimal? Hay n√™n 60% ho·∫∑c 80%?
- 1000 req/target c√≥ qu√° cao? (scale out mu·ªôn ‚Üí latency spike)
- Cooldown 300s c√≥ qu√° l√¢u? (waste resources khi traffic drop)

**Mitigation:**
- Load testing ƒë·ªÉ validate thresholds
- CloudWatch Insights ƒë·ªÉ analyze scaling patterns
- Iterative tuning (adjust sau 1-2 tu·∫ßn production data)

### 4. Database Connection Pool - Potential Bottleneck (Addressed)
**Problem:**
- 10 tasks √ó 5 connections/task = 50 connections
- RDS t3.micro max_connections = 87
- Headroom: 87 - 50 = 37 connections (43% buffer)

**Mitigation:**
- HikariCP config: `max_pool_size=5, min_idle=2` (per task)
- Monitor RDS DatabaseConnections metric
- Alert khi > 70 connections (80% threshold)

## K·∫øt qu·∫£ (D·ª± ki·∫øn - sau Load Testing)

### Performance Improvement
| Metric                | Before (1 task) | After (auto-scale) | Improvement |
|-----------------------|-----------------|-------------------|-------------|
| Throughput (RPS)      | 100             | 450               | **+350%**   |
| Latency p95 (create)  | 500ms           | 300ms             | **-40%**    |
| Latency p95 (history) | 800ms           | 120ms             | **-85%**    |
| Failure Rate          | 5% @ 100 users  | 0% @ 500 users    | **-100%**   |

### Scaling Behavior (Observed in Load Test)
```
Timeline:
00:00 - Start load test, 1 task running
02:00 - CPU 75%, trigger scale-out
02:30 - 2nd task running (90s cold start)
04:00 - CPU 72%, 2 tasks stable
10:00 - Traffic increases, CPU 75%
10:30 - Scale to 3 tasks
15:00 - Peak traffic, 5 tasks running (CPU 68%)
20:00 - Traffic drops, CPU 50%
25:00 - Scale in to 4 tasks (300s cooldown)
30:00 - Stable at 3 tasks
```

### Cost Analysis
**Scenario: Typical day**
- Off-peak (18 hours): 1 task √ó 3 services √ó $0.05/hour √ó 18 = $2.70
- Peak (6 hours): 5 tasks √ó 3 services √ó $0.05/hour √ó 6 = $4.50
- **Total**: $7.20/day = ~$216/month

**vs Fixed 3 tasks 24/7:**
- 3 tasks √ó 3 services √ó $0.05/hour √ó 24 √ó 30 = $324/month
- **Savings**: $108/month (33%)

## So s√°nh Ph∆∞∆°ng √°n

### Option 1: Target Tracking (Chosen) ‚úÖ
- **Pros**: T·ª± ƒë·ªông, d·ªÖ config, AWS managed
- **Cons**: Cold start delay, tuning complexity

### Option 2: Step Scaling (Rejected) ‚ùå
- **Pros**: Fine-grained control (v√≠ d·ª•: CPU 70% ‚Üí +1 task, CPU 85% ‚Üí +3 tasks)
- **Cons**: Ph·ª©c t·∫°p h∆°n, d·ªÖ misconfiguration, kh√¥ng t·ª± ƒë·ªông adjust target

### Option 3: Scheduled Scaling (Hybrid - Future) üîÑ
- **Pros**: Predictable cost, no cold start (scale tr∆∞·ªõc peak)
- **Cons**: Y√™u c·∫ßu bi·∫øt traffic pattern (data-driven)
- **Decision**: Combine v·ªõi Target Tracking sau khi c√≥ production data

## T√†i li·ªáu tham kh·∫£o

- [AWS ECS Auto Scaling](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-auto-scaling.html)
- [Target Tracking Scaling Policies](https://docs.aws.amazon.com/autoscaling/application/userguide/application-auto-scaling-target-tracking.html)
- [Fargate Task CPU/Memory Configurations](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/AWS_Fargate.html)

## L·ªãch s·ª≠

- **2024-11-20**: ƒê∆∞·ª£c ch·∫•p nh·∫≠n v√† implement trong Module A
- **Ng∆∞·ªùi quy·∫øt ƒë·ªãnh**: Nguy·ªÖn Qu·ªëc B·∫£o (Role B - Platform Engineer)
- **Next Steps**: Load testing validation by Role A (Nguy·ªÖn Vi·ªát Khoa)
- **Review Cycle**: Tune thresholds sau 2 tu·∫ßn production data
